{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import unicodedata\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/names/Arabic.txt', './data/names/English.txt', './data/names/German.txt', './data/names/Vietnamese.txt', './data/names/Italian.txt', './data/names/Czech.txt', './data/names/Scottish.txt', './data/names/Dutch.txt', './data/names/Korean.txt', './data/names/Chinese.txt', './data/names/Greek.txt', './data/names/Irish.txt', './data/names/French.txt', './data/names/Portuguese.txt', './data/names/Russian.txt', './data/names/Japanese.txt', './data/names/Polish.txt', './data/names/Spanish.txt']\n"
     ]
    }
   ],
   "source": [
    "def find_files(path): return glob.glob(path)\n",
    "print(find_files('./data/names/*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicode2ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "print(unicode2ascii(\"Ślusàrski\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def read_lines(filename):\n",
    "    lines = open(filename).read().strip().split('\\n')\n",
    "    return [unicode2ascii(line) for line in lines]\n",
    "\n",
    "for filename in find_files('./data/names/*.txt'):\n",
    "    category = filename.split('/')[-1].split('.')[0]\n",
    "    all_categories.append(category)\n",
    "    lines = read_lines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letter2index(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letter2tensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letter2index(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def line2tensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letter2index(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "print(line2tensor('keon').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_letters: 57 n_hidden: 128 n_categories: 18\n",
      "RNN (\n",
      "  (x2u): Linear (57 -> 128)\n",
      "  (c2g): Linear (185 -> 128)\n",
      "  (c2q): Linear (185 -> 128)\n",
      "  (out): Linear (128 -> 18)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RWA(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RWA, self).__init__()\n",
    "        \n",
    "        self.max_steps = 1\n",
    "        self.batch_size = 1\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.n = Variable(torch.Tensor(self.batch_size, hidden_size), requires_grad=True)\n",
    "        self.d = Variable(torch.Tensor(self.batch_size, hidden_size), requires_grad=True)\n",
    "        \n",
    "        self.x2u = nn.Linear(input_size, hidden_size)\n",
    "        self.c2g = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.c2q = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        h = F.tanh(hidden)\n",
    "        \n",
    "        for i in range(len(input)):\n",
    "            combined = torch.cat((input[i], h), 1)\n",
    "            \n",
    "            \n",
    "            u = self.x2u(input[i])\n",
    "            g = self.c2g(combined)\n",
    "            q = self.c2q(combined)\n",
    "            q_greater = F.relu(q)\n",
    "            scale = torch.exp(-q_greater)\n",
    "            a_scale = torch.exp(q-q_greater)\n",
    "            self.n = (self.n * scale) + ((u * F.tanh(g)) * a_scale)\n",
    "            self.d = (self.d * scale) + a_scale\n",
    "            h = F.tanh(torch.div(self.n, self.d))\n",
    "        output = self.out(h)\n",
    "        return output, h\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.randn(1, self.hidden_size))\n",
    "\n",
    "n_hidden = 128\n",
    "rwa = RWA(n_letters, n_hidden, n_categories)\n",
    "print(\"n_letters:\", n_letters, \"n_hidden:\", n_hidden, \"n_categories:\", n_categories)\n",
    "print(rwa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      "-0.2181  0.1584  0.0678  0.1462 -0.2016  0.0297 -0.0068  0.1225 -0.1715  0.1818\n",
      "\n",
      "Columns 10 to 17 \n",
      " 0.4594  0.0848  0.2152 -0.3734 -0.1102  0.1573 -0.0488  0.0308\n",
      "[torch.FloatTensor of size 1x18]\n",
      " Variable containing:\n",
      "\n",
      "Columns 0 to 5 \n",
      " 1.8044e-03  1.9991e-02  3.1786e-03  2.6121e-03  1.6083e-02  1.2365e-03\n",
      "\n",
      "Columns 6 to 11 \n",
      "-6.8232e-03 -5.7148e-03 -5.0756e-03  9.6675e-03 -2.3871e-03  3.2704e-03\n",
      "\n",
      "Columns 12 to 17 \n",
      " 6.2080e-03 -5.1337e-03 -6.1500e-03  8.9973e-03  4.4000e-03 -6.0094e-03\n",
      "\n",
      "Columns 18 to 23 \n",
      " 1.0000e+00  1.0000e+00 -1.5707e-03 -2.6361e-02 -8.2430e-03 -6.7953e-03\n",
      "\n",
      "Columns 24 to 29 \n",
      " 1.3388e-02  1.9324e-02  1.0000e+00 -4.1651e-03  6.8685e-03  7.1560e-03\n",
      "\n",
      "Columns 30 to 35 \n",
      "-1.0000e+00  5.2513e-03  7.3723e-13  1.1183e-02  7.1851e-03 -2.0261e-09\n",
      "\n",
      "Columns 36 to 41 \n",
      "-1.8267e-04  2.3346e-03 -8.1337e-25 -4.4789e-29 -1.7496e-03 -7.9274e-03\n",
      "\n",
      "Columns 42 to 47 \n",
      " 8.9760e-03  7.7648e-03  3.7587e-12  1.1966e-02 -6.3236e-22 -5.5934e-32\n",
      "\n",
      "Columns 48 to 53 \n",
      " 5.2877e-03 -1.1087e-02 -7.0549e-03 -4.5432e-03  2.4279e-03 -7.3531e-04\n",
      "\n",
      "Columns 54 to 59 \n",
      " 8.5024e-03 -9.4322e-03 -1.0000e+00  6.4231e-03 -1.0000e+00  1.0000e+00\n",
      "\n",
      "Columns 60 to 65 \n",
      "-1.7315e-02  1.6034e-02 -5.8387e-02 -1.0000e+00  6.1529e-03 -1.4865e-02\n",
      "\n",
      "Columns 66 to 71 \n",
      "-1.1457e-02 -2.4480e-02 -2.2122e-02  2.0225e-02  2.6484e-21 -4.0805e-03\n",
      "\n",
      "Columns 72 to 77 \n",
      " 6.5488e-03  2.6401e-03  2.3826e-03 -8.2996e-03 -1.0000e+00 -4.4558e-03\n",
      "\n",
      "Columns 78 to 83 \n",
      " 4.2397e-03  1.0000e+00 -2.7602e-03 -5.1401e-03 -2.6564e-02 -1.5074e-02\n",
      "\n",
      "Columns 84 to 89 \n",
      "-1.1278e-02  6.5806e-03 -6.7134e-03  1.4513e-02 -1.2433e-03  2.4292e-03\n",
      "\n",
      "Columns 90 to 95 \n",
      "-1.0000e+00 -1.6020e-03  1.3459e-02  1.7996e-02 -1.1401e-02 -1.0000e+00\n",
      "\n",
      "Columns 96 to 101 \n",
      "-6.9368e-03 -4.0204e-04  1.0000e+00 -1.5946e-04  3.1256e-02  8.4680e-04\n",
      "\n",
      "Columns 102 to 107 \n",
      "-1.0000e+00 -1.0000e+00 -3.4988e-02  9.2587e-04  4.3960e-03  1.0000e+00\n",
      "\n",
      "Columns 108 to 113 \n",
      "-6.5921e-03 -1.8774e-03 -3.1387e-03 -1.0000e+00 -5.5573e-04 -2.2458e-02\n",
      "\n",
      "Columns 114 to 119 \n",
      "-2.7465e-02  1.1549e-04 -2.0672e-03  4.8679e-03  4.1156e-03  1.5359e-02\n",
      "\n",
      "Columns 120 to 125 \n",
      "-6.4812e-03  6.6902e-04 -6.9493e-03 -5.5141e-03 -4.5913e-03 -3.4379e-03\n",
      "\n",
      "Columns 126 to 127 \n",
      " 1.0000e+00 -1.9925e-02\n",
      "[torch.FloatTensor of size 1x128]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input = Variable(line2tensor('Keon'))\n",
    "hidden = rwa.init_hidden()\n",
    "\n",
    "output, next_hidden = rwa(input, hidden)\n",
    "print(output, next_hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Greek', 10)\n"
     ]
    }
   ],
   "source": [
    "def category_from_output(output):\n",
    "    top_n, top_i = output.data.topk(1) # Tensor out of Variable with .data\n",
    "    category_i = top_i[0][0]\n",
    "    return all_categories[category_i], category_i\n",
    "print(category_from_output(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category : Czech  \tname: MaxaB\n",
      "category : Polish  \tname: Jedynak\n",
      "category : Scottish  \tname: White\n",
      "category : Japanese  \tname: Obata\n",
      "category : Japanese  \tname: Kaza\n",
      "category : Greek  \tname: Anetakis\n",
      "category : Greek  \tname: Spyridis\n",
      "category : German  \tname: Wegner\n",
      "category : Chinese  \tname: Yang\n",
      "category : Polish  \tname: Winogrodzki\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def choose(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def training_pair():                                                                                                               \n",
    "    category = choose(all_categories)\n",
    "    line = choose(category_lines[category])\n",
    "    category_tensor = Variable(torch.LongTensor([all_categories.index(category)]))\n",
    "    line_tensor = Variable(line2tensor(line))\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "for i in range(10):\n",
    "    category, line, category_tensor, line_tensor = training_pair()\n",
    "    print('category :', category, ' \\tname:', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "def train (categroy_tensor, line_tensor):\n",
    "    hidden = rwa.init_hidden()\n",
    "    hidden = Variable(hidden.data)\n",
    "    rwa.zero_grad()\n",
    "    output, hidden = rwa(line_tensor, hidden)\n",
    "    loss = criterion(output, category_tensor)\n",
    "    print(\"loss:\" , loss)\n",
    "    loss.backward()\n",
    "    \n",
    "    for p in rwa.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "    return output, loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: Variable containing:\n",
      "nan\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "loss: Variable containing:\n",
      "nan\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph second time, but the buffers have already been freed. Please specify retain_variables=True when calling backward for the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-073430d96222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-214-4bee22e367f7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(categroy_tensor, line_tensor)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss:\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_variables)\u001b[0m\n\u001b[1;32m    143\u001b[0m                     'or with gradient w.r.t. the variable')\n\u001b[1;32m    144\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/_functions/basic_ops.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph second time, but the buffers have already been freed. Please specify retain_variables=True when calling backward for the first time."
     ]
    }
   ],
   "source": [
    "n_epochs = 100000\n",
    "print_every = 5000\n",
    "plot_every = 1000\n",
    "\n",
    "rwa = RWA(n_letters, n_hidden, n_categories)\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def time_since(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    category, line, category_tensor, line_tensor = training_pair()\n",
    "    output, loss = train(category_tensor, line_tensor)\n",
    "    current_loss += loss\n",
    "\n",
    "    # Print epoch number, loss, name and guess\n",
    "    if epoch % print_every == 0:\n",
    "        guess, guess_i = category_from_output(output)\n",
    "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "        print('%d %d%% (%s) %.4f %s / %s %s' % (epoch, epoch / n_epochs * 100, time_since(start), loss, line, guess, correct))\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
